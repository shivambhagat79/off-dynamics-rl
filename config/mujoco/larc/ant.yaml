alpha: 0.2
batch_size: 128
actor_lr: 0.0003
critic_lr: 0.0003
gamma: 0.99

#
q_lr: 0.0003
cls_lr: 0.0003
policy_lr: 0.0003
darc_lambda: 0.5
liberty_eta: 0.5

classifier_lr: 0.0003
inv_loss_coeff: 0.08
fwd_loss_coeff: 0.2
metric_loss_coeff: 1.0
hidden_size: 256
liberty_policy_lr: 0.001
#

liberty_lr: 0.001
intrinsic_reward_coef: 1.0

target_policy_train_ratio: 10
aux_update_freq: 5

state_dim: 17
action_dim: 3
hidden_sizes: 256
max_action: 1

gaussian_noise_std: 1.0
penalty_coefficient: 1.0

temperature_opt: False

tau: 0.005
update_interval: 2
expl_noise: 0.2

eval_episode: 10
eval_freq: 10000
start_steps: 5000
max_step: 1000000
tar_env_interact_freq: 10

device: cuda

save_freq: 5000
